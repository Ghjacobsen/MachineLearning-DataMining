{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d0e6343b583f7f",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-09T12:44:43.076211Z",
     "start_time": "2025-04-09T12:44:39.117736Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from scipy.stats import ttest_rel, t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   index   User_ID  Gender  Age  Height  Weight  Duration  Heart_Rate  \\\n0      0  14733363       1   68   190.0    94.0      29.0       105.0   \n1      1  14861698       0   20   166.0    60.0      14.0        94.0   \n2      2  11179863       1   69   179.0    79.0       5.0        88.0   \n3      3  16180408       0   34   179.0    71.0      13.0       100.0   \n4      4  17771927       0   27   154.0    58.0      10.0        81.0   \n\n   Body_Temp  Calories  \n0       40.8     231.0  \n1       40.3      66.0  \n2       38.7      26.0  \n3       40.5      71.0  \n4       39.8      35.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>User_ID</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Height</th>\n      <th>Weight</th>\n      <th>Duration</th>\n      <th>Heart_Rate</th>\n      <th>Body_Temp</th>\n      <th>Calories</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>14733363</td>\n      <td>1</td>\n      <td>68</td>\n      <td>190.0</td>\n      <td>94.0</td>\n      <td>29.0</td>\n      <td>105.0</td>\n      <td>40.8</td>\n      <td>231.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>14861698</td>\n      <td>0</td>\n      <td>20</td>\n      <td>166.0</td>\n      <td>60.0</td>\n      <td>14.0</td>\n      <td>94.0</td>\n      <td>40.3</td>\n      <td>66.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>11179863</td>\n      <td>1</td>\n      <td>69</td>\n      <td>179.0</td>\n      <td>79.0</td>\n      <td>5.0</td>\n      <td>88.0</td>\n      <td>38.7</td>\n      <td>26.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>16180408</td>\n      <td>0</td>\n      <td>34</td>\n      <td>179.0</td>\n      <td>71.0</td>\n      <td>13.0</td>\n      <td>100.0</td>\n      <td>40.5</td>\n      <td>71.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>17771927</td>\n      <td>0</td>\n      <td>27</td>\n      <td>154.0</td>\n      <td>58.0</td>\n      <td>10.0</td>\n      <td>81.0</td>\n      <td>39.8</td>\n      <td>35.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calories = pd.read_csv('../Dataset/calories.csv')\n",
    "exercise = pd.read_csv('../Dataset/exercise.csv')\n",
    "df = pd.merge(exercise, calories, on = 'User_ID')\n",
    "#Mapper male til 1 og kvinder til 0 for at spare data\n",
    "df['Gender'] = df['Gender'].map({'male': 1, 'female': 0})\n",
    "df = df.reset_index()\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T12:44:43.099996Z",
     "start_time": "2025-04-09T12:44:43.077915Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 2\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67331e2929610872"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy = 0.5037\n",
      "\n",
      "Logistic Regression (varying λ):\n",
      "  λ=0.01 => Accuracy = 0.9173\n",
      "  λ=0.1 => Accuracy = 0.9173\n",
      "  λ=1 => Accuracy = 0.9173\n",
      "  λ=10 => Accuracy = 0.9177\n",
      "  λ=100 => Accuracy = 0.9180\n",
      "  λ=150 => Accuracy = 0.9183\n",
      "  λ=175 => Accuracy = 0.9187\n",
      "  λ=200 => Accuracy = 0.9183\n",
      "  λ=225 => Accuracy = 0.9183\n",
      "  λ=250 => Accuracy = 0.9183\n",
      "  λ=400 => Accuracy = 0.9180\n",
      "\n",
      "KNN (varying k):\n",
      "  k=1 => Accuracy = 0.8887\n",
      "  k=3 => Accuracy = 0.9077\n",
      "  k=5 => Accuracy = 0.9023\n",
      "  k=7 => Accuracy = 0.9053\n",
      "  k=9 => Accuracy = 0.9020\n",
      "  k=11 => Accuracy = 0.9043\n",
      "  k=13 => Accuracy = 0.9060\n",
      "  k=15 => Accuracy = 0.9033\n"
     ]
    }
   ],
   "source": [
    "# DEFINE FEATURES\n",
    "X = df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories']]  \n",
    "y = df['Gender']\n",
    "\n",
    "# SPLIT INTO TRAIN AND TEST SETS\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y)\n",
    "\n",
    "# BASELINE MODEL\n",
    "majority_class = y_train.value_counts().idxmax()\n",
    "y_pred_baseline = np.full(shape=len(y_test), fill_value=majority_class)\n",
    "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
    "print(f\"Baseline Accuracy = {baseline_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# LOGISTIC REGRESSION\n",
    "\n",
    "lambdas = [0.01, 0.1, 1, 10, 100, 150, 175, 200, 225, 250, 400]\n",
    "logreg_accuracies = []\n",
    "\n",
    "for lam in lambdas:\n",
    "    if lam == 0:\n",
    "        continue\n",
    "    \n",
    "    C_val = 1.0 / lam\n",
    "    \n",
    "    logreg = LogisticRegression(penalty='l2',\n",
    "                                C=C_val, \n",
    "                                solver='lbfgs', \n",
    "                                max_iter=1000,\n",
    "                                random_state=42)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    logreg_accuracies.append((lam, acc))\n",
    "\n",
    "# Print logistic regression results\n",
    "print(\"\\nLogistic Regression (varying λ):\")\n",
    "for (lam, acc) in logreg_accuracies:\n",
    "    print(f\"  λ={lam} => Accuracy = {acc:.4f}\")\n",
    "\n",
    "# KNN CLASSIFIER\n",
    "\n",
    "k_values = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "knn_accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_knn = knn.predict(X_test)\n",
    "    acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "    knn_accuracies.append((k, acc_knn))\n",
    "\n",
    "# Print  results\n",
    "print(\"\\nKNN (varying k):\")\n",
    "for (k, acc) in knn_accuracies:\n",
    "    print(f\"  k={k} => Accuracy = {acc:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T12:44:44.367372Z",
     "start_time": "2025-04-09T12:44:43.105178Z"
    }
   },
   "id": "8173bfc0b740a326"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 3\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b23a524c0feb4045"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Two-Level Cross-Validation Results:\n",
      "\n",
      "   Fold  lambda*  LogReg Error  k*  KNN Error  Baseline Error\n",
      "0     1   0.0001      0.092667   1   0.119333        0.496667\n",
      "1     2   0.0001      0.068000   1   0.098000        0.496667\n",
      "2     3  10.0000      0.088000   1   0.106000        0.496667\n",
      "3     4   0.0001      0.086667   1   0.118000        0.496667\n",
      "4     5   0.0001      0.090000   1   0.111333        0.496667\n",
      "5     6  10.0000      0.090667   1   0.108000        0.496667\n",
      "6     7   1.0000      0.083333   1   0.118667        0.496667\n",
      "7     8   0.0001      0.084000   1   0.118000        0.496000\n",
      "8     9   0.0001      0.091333   1   0.117333        0.496000\n",
      "9    10   1.0000      0.068667   1   0.113333        0.496000\n",
      "\n",
      "Average test errors across outer folds:\n",
      "  Logistic Regression: 0.0843\n",
      "  KNN:                0.1128\n",
      "  Baseline:           0.4965\n"
     ]
    }
   ],
   "source": [
    "# Define an error scorer \n",
    "def error_rate(y_true, y_pred):\n",
    "    return 1.0 - accuracy_score(y_true, y_pred)\n",
    "\n",
    "error_scorer = make_scorer(error_rate, greater_is_better=True)\n",
    "\n",
    "# Outer Cross-validation Setup\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)  \n",
    "\n",
    "results = {\n",
    "    'Fold': [],\n",
    "    'lambda*': [], 'LogReg Error': [],\n",
    "    'k*': [],      'KNN Error': [],\n",
    "    'Baseline Error': []\n",
    "}\n",
    "\n",
    "# Define the hyperparameter grids\n",
    "log_lambdas = [0.0001, 0.001, 0.01, 0.1, 1, 10]  \n",
    "log_param_grid = {'C': [1.0 / lam for lam in log_lambdas]}\n",
    "\n",
    "knn_k_values = [1, 3, 5, 7, 9, 11, 13]\n",
    "knn_param_grid = {'n_neighbors': knn_k_values}\n",
    "\n",
    "\n",
    "#Outer Loop for final evaluatioin\n",
    "fold_idx = 1\n",
    "for train_index, test_index in outer_cv.split(X, y):\n",
    "    X_train_outer, X_test_outer = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train_outer, y_test_outer = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    majority_class = y_train_outer.value_counts().idxmax()\n",
    "    baseline_preds = np.full_like(y_test_outer, majority_class)\n",
    "    baseline_error = error_rate(y_test_outer, baseline_preds)\n",
    "\n",
    "    logreg = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "    inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)  \n",
    "    logreg_gs = GridSearchCV(estimator=logreg,\n",
    "                             param_grid=log_param_grid,\n",
    "                             scoring=error_scorer,   \n",
    "                             cv=inner_cv,\n",
    "                             n_jobs=-1)\n",
    "    logreg_gs.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "    # Best logistic regression model on this outer fold\n",
    "    best_logreg = logreg_gs.best_estimator_\n",
    "    logreg_preds = best_logreg.predict(X_test_outer)\n",
    "    logreg_error = error_rate(y_test_outer, logreg_preds)\n",
    "\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn_gs = GridSearchCV(estimator=knn,\n",
    "                          param_grid=knn_param_grid,\n",
    "                          scoring=error_scorer,\n",
    "                          cv=inner_cv,\n",
    "                          n_jobs=-1)\n",
    "    knn_gs.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "    best_knn = knn_gs.best_estimator_\n",
    "    knn_preds = best_knn.predict(X_test_outer)\n",
    "    knn_error = error_rate(y_test_outer, knn_preds)\n",
    "\n",
    "    # Collect results for this outer fold\n",
    "    chosen_lambda = 1.0 / best_logreg.C\n",
    "    chosen_k = best_knn.n_neighbors\n",
    "\n",
    "    results['Fold'].append(fold_idx)\n",
    "    results['lambda*'].append(chosen_lambda)\n",
    "    results['LogReg Error'].append(logreg_error)\n",
    "    results['k*'].append(chosen_k)\n",
    "    results['KNN Error'].append(knn_error)\n",
    "    results['Baseline Error'].append(baseline_error)\n",
    "\n",
    "    fold_idx += 1\n",
    "\n",
    "# Create a results DataFrame \n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nTwo-Level Cross-Validation Results:\\n\")\n",
    "print(results_df)\n",
    "\n",
    "# Compute average errors across folds \n",
    "avg_logreg_err = results_df['LogReg Error'].mean()\n",
    "avg_knn_err = results_df['KNN Error'].mean()\n",
    "avg_base_err = results_df['Baseline Error'].mean()\n",
    "\n",
    "print(\"\\nAverage test errors across outer folds:\")\n",
    "print(f\"  Logistic Regression: {avg_logreg_err:.4f}\")\n",
    "print(f\"  KNN:                {avg_knn_err:.4f}\")\n",
    "print(f\"  Baseline:           {avg_base_err:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T12:44:51.936405Z",
     "start_time": "2025-04-09T12:44:44.371913Z"
    }
   },
   "id": "576cd1b0203884bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 4\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c04057a4ef80afc3"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Paired T-Tests on Error Rates:\n",
      "\n",
      "Logistic Regression vs KNN:\n",
      "  Mean diff (LR - KNN): -0.0285\n",
      "  95% CI for diff:      [-0.0345, -0.0224]\n",
      "  p-value:              2.1339e-06\n",
      "  t-statistic:          -10.6378\n",
      "\n",
      "Logistic Regression vs Baseline:\n",
      "  Mean diff (LR - Baseline): -0.4121\n",
      "  95% CI for diff:           [-0.4185, -0.4058]\n",
      "  p-value:                   1.6307e-16\n",
      "  t-statistic:               -146.5457\n",
      "\n",
      "KNN vs Baseline:\n",
      "  Mean diff (KNN - Baseline): -0.3837\n",
      "  95% CI for diff:            [-0.3888, -0.3786]\n",
      "  p-value:                    4.2339e-17\n",
      "  t-statistic:                -170.2411\n"
     ]
    }
   ],
   "source": [
    "# Extract the vectors of errrors\n",
    "logreg_err = results_df['LogReg Error'].values\n",
    "knn_err = results_df['KNN Error'].values\n",
    "baseline_err = results_df['Baseline Error'].values\n",
    "\n",
    "def paired_ttest_with_ci(a, b, alpha=0.05):\n",
    "    # Differences per fold\n",
    "    d = a - b\n",
    "    n = len(d)\n",
    "    d_mean = np.mean(d)\n",
    "    d_std = np.std(d, ddof=1)          \n",
    "   \n",
    "    t_stat, p_value = ttest_rel(a, b)\n",
    "    \n",
    "    t_crit = t.ppf(1 - alpha/2, df=n - 1)\n",
    "   \n",
    "    half_width = t_crit * (d_std / np.sqrt(n))\n",
    "    ci_lower = d_mean - half_width\n",
    "    ci_upper = d_mean + half_width\n",
    "    return d_mean, p_value, (ci_lower, ci_upper), t_stat\n",
    "\n",
    "#Pairwice comparisons\n",
    "#   Logistic Regression vs KNN\n",
    "diff_lr_knn, p_lr_knn, ci_lr_knn, tstat_lr_knn = paired_ttest_with_ci(logreg_err, knn_err)\n",
    "\n",
    "#   Logistic Regression vs Baseline\n",
    "diff_lr_base, p_lr_base, ci_lr_base, tstat_lr_base = paired_ttest_with_ci(logreg_err, baseline_err)\n",
    "\n",
    "#   KNN vs Baseline\n",
    "diff_knn_base, p_knn_base, ci_knn_base, tstat_knn_base = paired_ttest_with_ci(knn_err, baseline_err)\n",
    "\n",
    "# Print results\n",
    "print(\"Pairwise Paired T-Tests on Error Rates:\\n\")\n",
    "\n",
    "print(f\"Logistic Regression vs KNN:\")\n",
    "print(f\"  Mean diff (LR - KNN): {diff_lr_knn:.4f}\")\n",
    "print(f\"  95% CI for diff:      [{ci_lr_knn[0]:.4f}, {ci_lr_knn[1]:.4f}]\")\n",
    "print(f\"  p-value:              {p_lr_knn:.4e}\")\n",
    "print(f\"  t-statistic:          {tstat_lr_knn:.4f}\\n\")\n",
    "\n",
    "print(f\"Logistic Regression vs Baseline:\")\n",
    "print(f\"  Mean diff (LR - Baseline): {diff_lr_base:.4f}\")\n",
    "print(f\"  95% CI for diff:           [{ci_lr_base[0]:.4f}, {ci_lr_base[1]:.4f}]\")\n",
    "print(f\"  p-value:                   {p_lr_base:.4e}\")\n",
    "print(f\"  t-statistic:               {tstat_lr_base:.4f}\\n\")\n",
    "\n",
    "print(f\"KNN vs Baseline:\")\n",
    "print(f\"  Mean diff (KNN - Baseline): {diff_knn_base:.4f}\")\n",
    "print(f\"  95% CI for diff:            [{ci_knn_base[0]:.4f}, {ci_knn_base[1]:.4f}]\")\n",
    "print(f\"  p-value:                    {p_knn_base:.4e}\")\n",
    "print(f\"  t-statistic:                {tstat_knn_base:.4f}\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T12:44:51.944687Z",
     "start_time": "2025-04-09T12:44:51.938954Z"
    }
   },
   "id": "3750a51965c69e18"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T12:44:51.944956Z",
     "start_time": "2025-04-09T12:44:51.942509Z"
    }
   },
   "id": "88a06a532e18ccc5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b973759544b71d2"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen λ (lambda): 0.1\n",
      "Corresponding C   : 10.0\n",
      "\n",
      "Logistic Regression Coefficients:\n",
      "  Age: -0.0454\n",
      "  Height: -0.2918\n",
      "  Weight: 0.5861\n",
      "  Duration: -0.0398\n",
      "  Heart_Rate: 0.0063\n",
      "  Body_Temp: 0.2273\n",
      "  Calories: 0.0020\n",
      "Intercept (bias): 0.0057\n"
     ]
    }
   ],
   "source": [
    "# Choose a suitable value of lambda (λ) \n",
    "best_lambda = 0.1\n",
    "C_val = 1.0 / best_lambda\n",
    "\n",
    "# Define our features and target\n",
    "X = df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories']]\n",
    "y = df['Gender']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train logistic regression\n",
    "logreg = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=C_val,\n",
    "    solver='lbfgs',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "#  Show how the logistic model makes predictions\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Examine the learned coefficients\n",
    "features = X.columns\n",
    "coef_values = logreg.coef_.flatten()  \n",
    "intercept_value = logreg.intercept_[0]\n",
    "\n",
    "print(\"Chosen λ (lambda):\", best_lambda)\n",
    "print(\"Corresponding C   :\", C_val)\n",
    "print(\"\\nLogistic Regression Coefficients:\")\n",
    "for feat, val in zip(features, coef_values):\n",
    "    print(f\"  {feat}: {val:.4f}\")\n",
    "print(f\"Intercept (bias): {intercept_value:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T12:44:52.069465Z",
     "start_time": "2025-04-09T12:44:51.945033Z"
    }
   },
   "id": "b3d3c2f739b45c37"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T12:44:52.076189Z",
     "start_time": "2025-04-09T12:44:52.070755Z"
    }
   },
   "id": "4fa2ba1aafb15377"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
