{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-02T08:32:08.985097Z",
     "start_time": "2025-04-02T08:32:08.641531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   index   User_ID  Gender  Age  Height  Weight  Duration  Heart_Rate  \\\n0      0  14733363       1   68   190.0    94.0      29.0       105.0   \n1      1  14861698       0   20   166.0    60.0      14.0        94.0   \n2      2  11179863       1   69   179.0    79.0       5.0        88.0   \n3      3  16180408       0   34   179.0    71.0      13.0       100.0   \n4      4  17771927       0   27   154.0    58.0      10.0        81.0   \n\n   Body_Temp  Calories  \n0       40.8     231.0  \n1       40.3      66.0  \n2       38.7      26.0  \n3       40.5      71.0  \n4       39.8      35.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>User_ID</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Height</th>\n      <th>Weight</th>\n      <th>Duration</th>\n      <th>Heart_Rate</th>\n      <th>Body_Temp</th>\n      <th>Calories</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>14733363</td>\n      <td>1</td>\n      <td>68</td>\n      <td>190.0</td>\n      <td>94.0</td>\n      <td>29.0</td>\n      <td>105.0</td>\n      <td>40.8</td>\n      <td>231.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>14861698</td>\n      <td>0</td>\n      <td>20</td>\n      <td>166.0</td>\n      <td>60.0</td>\n      <td>14.0</td>\n      <td>94.0</td>\n      <td>40.3</td>\n      <td>66.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>11179863</td>\n      <td>1</td>\n      <td>69</td>\n      <td>179.0</td>\n      <td>79.0</td>\n      <td>5.0</td>\n      <td>88.0</td>\n      <td>38.7</td>\n      <td>26.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>16180408</td>\n      <td>0</td>\n      <td>34</td>\n      <td>179.0</td>\n      <td>71.0</td>\n      <td>13.0</td>\n      <td>100.0</td>\n      <td>40.5</td>\n      <td>71.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>17771927</td>\n      <td>0</td>\n      <td>27</td>\n      <td>154.0</td>\n      <td>58.0</td>\n      <td>10.0</td>\n      <td>81.0</td>\n      <td>39.8</td>\n      <td>35.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "calories = pd.read_csv('../Dataset/calories.csv')\n",
    "exercise = pd.read_csv('../Dataset/exercise.csv')\n",
    "df = pd.merge(exercise, calories, on = 'User_ID')\n",
    "#Mapper male til 1 og kvinder til 0 for at spare data\n",
    "df['Gender'] = df['Gender'].map({'male': 1, 'female': 0})\n",
    "df = df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 2\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67331e2929610872"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy = 0.5037\n",
      "\n",
      "Logistic Regression (varying λ):\n",
      "  λ=0.01 => Accuracy = 0.9173\n",
      "  λ=0.1 => Accuracy = 0.9173\n",
      "  λ=1 => Accuracy = 0.9173\n",
      "  λ=10 => Accuracy = 0.9177\n",
      "  λ=100 => Accuracy = 0.9180\n",
      "  λ=150 => Accuracy = 0.9183\n",
      "  λ=175 => Accuracy = 0.9187\n",
      "  λ=200 => Accuracy = 0.9183\n",
      "  λ=225 => Accuracy = 0.9183\n",
      "  λ=250 => Accuracy = 0.9183\n",
      "  λ=400 => Accuracy = 0.9180\n",
      "\n",
      "KNN (varying k):\n",
      "  k=1 => Accuracy = 0.8887\n",
      "  k=3 => Accuracy = 0.9077\n",
      "  k=5 => Accuracy = 0.9023\n",
      "  k=7 => Accuracy = 0.9053\n",
      "  k=9 => Accuracy = 0.9020\n",
      "  k=11 => Accuracy = 0.9043\n",
      "  k=13 => Accuracy = 0.9060\n",
      "  k=15 => Accuracy = 0.9033\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 2. DEFINE FEATURES (X) AND TARGET (y)\n",
    "X = df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories']]  # Example features\n",
    "y = df['Gender']\n",
    "\n",
    "# 3. SPLIT INTO TRAIN AND TEST SETS\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y)\n",
    "\n",
    "# 4. BASELINE MODEL\n",
    "\n",
    "# Identify the majority class\n",
    "majority_class = y_train.value_counts().idxmax()\n",
    "\n",
    "# Predict the majority class for all test samples\n",
    "y_pred_baseline = np.full(shape=len(y_test), fill_value=majority_class)\n",
    "\n",
    "# Evaluate the baseline\n",
    "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
    "print(f\"Baseline Accuracy = {baseline_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# 5. LOGISTIC REGRESSION\n",
    "#\n",
    "#   We’ll vary λ >= 0. In scikit-learn, the regularization\n",
    "#   parameter is `C = 1/λ`. For example, we’ll examine a \n",
    "#   few values of λ below. \n",
    "\n",
    "lambdas = [0.01, 0.1, 1, 10, 100, 150, 175, 200, 225, 250, 400]\n",
    "logreg_accuracies = []\n",
    "\n",
    "for lam in lambdas:\n",
    "    if lam == 0:\n",
    "        continue\n",
    "    \n",
    "    C_val = 1.0 / lam\n",
    "    \n",
    "    logreg = LogisticRegression(penalty='l2',\n",
    "                                C=C_val, \n",
    "                                solver='lbfgs', \n",
    "                                max_iter=1000,\n",
    "                                random_state=42)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    logreg_accuracies.append((lam, acc))\n",
    "\n",
    "# Print logistic regression results\n",
    "print(\"\\nLogistic Regression (varying λ):\")\n",
    "for (lam, acc) in logreg_accuracies:\n",
    "    print(f\"  λ={lam} => Accuracy = {acc:.4f}\")\n",
    "\n",
    "###################################################\n",
    "# 6. KNN CLASSIFIER\n",
    "#\n",
    "#   For method 2, we use KNN. We’ll vary k (the #neighbors)\n",
    "#   as the complexity-controlling parameter.\n",
    "###################################################\n",
    "\n",
    "k_values = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "knn_accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_knn = knn.predict(X_test)\n",
    "    acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "    knn_accuracies.append((k, acc_knn))\n",
    "\n",
    "# Print KNN results\n",
    "print(\"\\nKNN (varying k):\")\n",
    "for (k, acc) in knn_accuracies:\n",
    "    print(f\"  k={k} => Accuracy = {acc:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-02T08:42:50.709390Z",
     "start_time": "2025-04-02T08:42:49.550542Z"
    }
   },
   "id": "8173bfc0b740a326"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 3\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b23a524c0feb4045"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Two-Level Cross-Validation Results:\n",
      "\n",
      "   Fold  lambda*  LogReg Error  k*  KNN Error  Baseline Error\n",
      "0     1   0.0001      0.092667   1   0.119333        0.496667\n",
      "1     2   0.0001      0.068000   1   0.098000        0.496667\n",
      "2     3  10.0000      0.088000   1   0.106000        0.496667\n",
      "3     4   0.0001      0.086667   1   0.118000        0.496667\n",
      "4     5   0.0001      0.090000   1   0.111333        0.496667\n",
      "5     6  10.0000      0.090667   1   0.108000        0.496667\n",
      "6     7   1.0000      0.083333   1   0.118667        0.496667\n",
      "7     8   0.0001      0.084000   1   0.118000        0.496000\n",
      "8     9   0.0001      0.091333   1   0.117333        0.496000\n",
      "9    10   1.0000      0.068667   1   0.113333        0.496000\n",
      "\n",
      "Average test errors across outer folds:\n",
      "  Logistic Regression: 0.0843\n",
      "  KNN:                0.1128\n",
      "  Baseline:           0.4965\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "# 2. Define an error scorer \n",
    "#    error = 1 - accuracy\n",
    "def error_rate(y_true, y_pred):\n",
    "    return 1.0 - accuracy_score(y_true, y_pred)\n",
    "\n",
    "error_scorer = make_scorer(error_rate, greater_is_better=True)\n",
    "\n",
    "# 3. Outer Cross-validation Setup\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)  # for example, 5 outer folds\n",
    "\n",
    "# We'll store results in a list/dict for making a final table.\n",
    "results = {\n",
    "    'Fold': [],\n",
    "    'lambda*': [], 'LogReg Error': [],\n",
    "    'k*': [],      'KNN Error': [],\n",
    "    'Baseline Error': []\n",
    "}\n",
    "\n",
    "# 4. Define the hyperparameter grids\n",
    "#    Note scikit-learn's 'C' = 1/lambda. We’ll invert below.\n",
    "log_lambdas = [0.0001, 0.001, 0.01, 0.1, 1, 10]  # Example range\n",
    "log_param_grid = {'C': [1.0 / lam for lam in log_lambdas]}\n",
    "\n",
    "knn_k_values = [1, 3, 5, 7, 9, 11, 13]\n",
    "knn_param_grid = {'n_neighbors': knn_k_values}\n",
    "\n",
    "\n",
    "# 5. Outer Loop for final evaluation\n",
    "fold_idx = 1\n",
    "for train_index, test_index in outer_cv.split(X, y):\n",
    "    X_train_outer, X_test_outer = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train_outer, y_test_outer = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # === BASELINE ===\n",
    "    majority_class = y_train_outer.value_counts().idxmax()\n",
    "    baseline_preds = np.full_like(y_test_outer, majority_class)\n",
    "    baseline_error = error_rate(y_test_outer, baseline_preds)\n",
    "\n",
    "    # === INNER CROSS-VALIDATION (Hyperparameter Tuning) ===\n",
    "    #  5a. Logistic Regression with GridSearch\n",
    "    logreg = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "    inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)  # for tuning\n",
    "    logreg_gs = GridSearchCV(estimator=logreg,\n",
    "                             param_grid=log_param_grid,\n",
    "                             scoring=error_scorer,   # measure error directly\n",
    "                             cv=inner_cv,\n",
    "                             n_jobs=-1)\n",
    "    logreg_gs.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "    # Best logistic regression model on this outer fold\n",
    "    best_logreg = logreg_gs.best_estimator_\n",
    "    # Evaluate on the outer test fold\n",
    "    logreg_preds = best_logreg.predict(X_test_outer)\n",
    "    logreg_error = error_rate(y_test_outer, logreg_preds)\n",
    "\n",
    "    #  5b. KNN with GridSearch\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn_gs = GridSearchCV(estimator=knn,\n",
    "                          param_grid=knn_param_grid,\n",
    "                          scoring=error_scorer,\n",
    "                          cv=inner_cv,\n",
    "                          n_jobs=-1)\n",
    "    knn_gs.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "    best_knn = knn_gs.best_estimator_\n",
    "    knn_preds = best_knn.predict(X_test_outer)\n",
    "    knn_error = error_rate(y_test_outer, knn_preds)\n",
    "\n",
    "    # 6. Collect results for this outer fold\n",
    "    # Extract \"best\" hyperparameters in the original scale (lambda, k)\n",
    "    # logistic: we have best_logreg.C => lambda = 1/C\n",
    "    chosen_lambda = 1.0 / best_logreg.C\n",
    "    chosen_k = best_knn.n_neighbors\n",
    "\n",
    "    results['Fold'].append(fold_idx)\n",
    "    results['lambda*'].append(chosen_lambda)\n",
    "    results['LogReg Error'].append(logreg_error)\n",
    "    results['k*'].append(chosen_k)\n",
    "    results['KNN Error'].append(knn_error)\n",
    "    results['Baseline Error'].append(baseline_error)\n",
    "\n",
    "    fold_idx += 1\n",
    "\n",
    "# 7. Create a results DataFrame resembling your “Table 2”\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nTwo-Level Cross-Validation Results:\\n\")\n",
    "print(results_df)\n",
    "\n",
    "# 8. Compute average errors across folds for final summary\n",
    "avg_logreg_err = results_df['LogReg Error'].mean()\n",
    "avg_knn_err = results_df['KNN Error'].mean()\n",
    "avg_base_err = results_df['Baseline Error'].mean()\n",
    "\n",
    "print(\"\\nAverage test errors across outer folds:\")\n",
    "print(f\"  Logistic Regression: {avg_logreg_err:.4f}\")\n",
    "print(f\"  KNN:                {avg_knn_err:.4f}\")\n",
    "print(f\"  Baseline:           {avg_base_err:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-02T09:03:07.541191Z",
     "start_time": "2025-04-02T09:03:01.335598Z"
    }
   },
   "id": "576cd1b0203884bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 4\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c04057a4ef80afc3"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_true_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 10\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Suppose you have your final predictions from each of the three models on the entire dataset,\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# each row corresponding to one data sample (never used in training for that model),\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# and columns = [\"Logistic\", \"KNN\", \"Baseline\"] plus the true label \"y_true\".\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# For example, you could store them as:\u001B[39;00m\n\u001B[1;32m      9\u001B[0m df_preds \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\n\u001B[0;32m---> 10\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m'\u001B[39m:       \u001B[43mall_true_labels\u001B[49m,          \u001B[38;5;66;03m# shape (N,)\u001B[39;00m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogreg_pred\u001B[39m\u001B[38;5;124m'\u001B[39m:  all_logreg_predictions,   \u001B[38;5;66;03m# shape (N,)\u001B[39;00m\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mknn_pred\u001B[39m\u001B[38;5;124m'\u001B[39m:     all_knn_predictions,      \u001B[38;5;66;03m# shape (N,)\u001B[39;00m\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbase_pred\u001B[39m\u001B[38;5;124m'\u001B[39m:    all_baseline_predictions, \u001B[38;5;66;03m# shape (N,)\u001B[39;00m\n\u001B[1;32m     14\u001B[0m })\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Check dimension\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(df_preds\u001B[38;5;241m.\u001B[39mshape)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'all_true_labels' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Suppose you have your final predictions from each of the three models on the entire dataset,\n",
    "# each row corresponding to one data sample (never used in training for that model),\n",
    "# and columns = [\"Logistic\", \"KNN\", \"Baseline\"] plus the true label \"y_true\".\n",
    "\n",
    "# For example, you could store them as:\n",
    "df_preds = pd.DataFrame({\n",
    "    'y_true':       all_true_labels,          # shape (N,)\n",
    "    'logreg_pred':  all_logreg_predictions,   # shape (N,)\n",
    "    'knn_pred':     all_knn_predictions,      # shape (N,)\n",
    "    'base_pred':    all_baseline_predictions, # shape (N,)\n",
    "})\n",
    "\n",
    "# Check dimension\n",
    "print(df_preds.shape)\n",
    "df_preds.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-02T09:30:10.761204Z",
     "start_time": "2025-04-02T09:30:10.736428Z"
    }
   },
   "id": "3537374089dca710"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Option A: statsmodels built-in\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "def run_mcnemar_test(y_true, predA, predB):\n",
    "    \"\"\"\n",
    "    Runs McNemar's test comparing two classifiers (A and B).\n",
    "    Returns the test statistic and p-value.\n",
    "    \"\"\"\n",
    "    # 1) Convert to 'correct' or 'incorrect' for each classifier\n",
    "    correctA = (predA == y_true).astype(int)\n",
    "    correctB = (predB == y_true).astype(int)\n",
    "\n",
    "    # 2) Construct the 2x2 contingency table\n",
    "    #    a01 = # data points: A correct, B wrong\n",
    "    #    a10 = # data points: A wrong, B correct\n",
    "    a01 = np.sum((correctA == 1) & (correctB == 0))\n",
    "    a10 = np.sum((correctA == 0) & (correctB == 1))\n",
    "\n",
    "    # statsmodels wants the table in this form:\n",
    "    # [[both_correct, a01],\n",
    "    #  [a10, both_wrong]]\n",
    "    # But for McNemar’s p-value, only a01 and a10 matter.\n",
    "    both_correct = np.sum((correctA == 1) & (correctB == 1))\n",
    "    both_wrong   = np.sum((correctA == 0) & (correctB == 0))\n",
    "    table = [[both_correct, a01],\n",
    "             [a10,         both_wrong]]\n",
    "\n",
    "    # 3) Run McNemar test (can choose exact or approximate)\n",
    "    result = mcnemar(table=table, exact=False, correction=True)  # continuity correction\n",
    "    return result.statistic, result.pvalue\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3750a51965c69e18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "88a06a532e18ccc5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b973759544b71d2"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error Rate (lambda=175) = 0.0813\n",
      "Coefficients (w): [[-4.19014625e-02 -2.65063534e-01  5.53112708e-01 -2.57832265e-02\n",
      "   1.21864425e-02  1.53195433e-01  1.02837791e-04]]\n",
      "Intercept (w0): [0.00344442]\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Logistic Regression with lambda = 175 => C ~ 0.0057\n",
    "lambda_val = 175\n",
    "C_val = 1.0 / lambda_val\n",
    "\n",
    "logreg = LogisticRegression(penalty='l2', C=C_val, solver='lbfgs', max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = logreg.predict(X_test)\n",
    "test_error = 1.0 - accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Error Rate (lambda={lambda_val}) = {test_error:.4f}\")\n",
    "\n",
    "# Inspect coefficients\n",
    "print(\"Coefficients (w):\", logreg.coef_)\n",
    "print(\"Intercept (w0):\", logreg.intercept_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-02T09:12:45.113908Z",
     "start_time": "2025-04-02T09:12:44.995555Z"
    }
   },
   "id": "b3d3c2f739b45c37"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4fa2ba1aafb15377"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
